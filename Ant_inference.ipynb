{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc64183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Ant_quant import *\n",
    "env = gym.make('Ant-v5')\n",
    "cfg = {\n",
    "        \"quant_act\": True,\n",
    "        \"quant_weights\": True,\n",
    "        \"activation\": \"relu\",\n",
    "    }\n",
    "model = PPO(\n",
    "        policy=QuantizedActorCriticPolicy,\n",
    "        env=env,\n",
    "        policy_kwargs={\"cfg\": cfg},\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"./ppo_tensorboard_ant/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af3f2e",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da1bb70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['log_std', 'mlp_extractor.policy_net.act1.x_min', 'mlp_extractor.policy_net.act1.x_max', 'mlp_extractor.policy_net.act1.act_scaling_factor', 'mlp_extractor.policy_net.act1.pre_weight_scaling_factor', 'mlp_extractor.policy_net.act1.identity_weight_scaling_factor', 'mlp_extractor.policy_net.fc1.weight', 'mlp_extractor.policy_net.fc1.bias', 'mlp_extractor.policy_net.fc1.fc_scaling_factor', 'mlp_extractor.policy_net.fc1.weight_integer', 'mlp_extractor.policy_net.fc1.bias_integer', 'mlp_extractor.policy_net.act2.x_min', 'mlp_extractor.policy_net.act2.x_max', 'mlp_extractor.policy_net.act2.act_scaling_factor', 'mlp_extractor.policy_net.act2.pre_weight_scaling_factor', 'mlp_extractor.policy_net.act2.identity_weight_scaling_factor', 'mlp_extractor.policy_net.fc2.weight', 'mlp_extractor.policy_net.fc2.bias', 'mlp_extractor.policy_net.fc2.fc_scaling_factor', 'mlp_extractor.policy_net.fc2.weight_integer', 'mlp_extractor.policy_net.fc2.bias_integer', 'mlp_extractor.policy_net.act3.x_min', 'mlp_extractor.policy_net.act3.x_max', 'mlp_extractor.policy_net.act3.act_scaling_factor', 'mlp_extractor.policy_net.act3.pre_weight_scaling_factor', 'mlp_extractor.policy_net.act3.identity_weight_scaling_factor', 'mlp_extractor.value_net.0.weight', 'mlp_extractor.value_net.0.bias', 'mlp_extractor.value_net.2.weight', 'mlp_extractor.value_net.2.bias', 'action_net.act1.x_min', 'action_net.act1.x_max', 'action_net.act1.act_scaling_factor', 'action_net.act1.pre_weight_scaling_factor', 'action_net.act1.identity_weight_scaling_factor', 'action_net.fc1.weight', 'action_net.fc1.bias', 'action_net.fc1.fc_scaling_factor', 'action_net.fc1.weight_integer', 'action_net.fc1.bias_integer', 'action_net.act2.x_min', 'action_net.act2.x_max', 'action_net.act2.act_scaling_factor', 'action_net.act2.pre_weight_scaling_factor', 'action_net.act2.identity_weight_scaling_factor', 'value_net.weight', 'value_net.bias'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/home/ritwik/MuJoCo_Quant/logs_ant/best_model_fixscale_1/best_model.zip\"\n",
    "import torch as th\n",
    "import zipfile\n",
    "import io\n",
    "from Ant_quant import *\n",
    "# Open the zip and load policy.pth\n",
    "with zipfile.ZipFile(model_path, \"r\") as archive:\n",
    "    with archive.open(\"policy.pth\", \"r\") as f:\n",
    "        state_dict = th.load(io.BytesIO(f.read()), map_location=\"cpu\")\n",
    "\n",
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c621d46e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for QuantizedActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.act1.x_min: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for mlp_extractor.policy_net.act1.x_max: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for mlp_extractor.policy_net.act1.act_scaling_factor: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for action_net.act2.x_min: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for action_net.act2.x_max: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for action_net.act2.act_scaling_factor: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ritwik/MuJoCo_Quant/logs_ant/best_model_fixscale_1/best_model.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cppo/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:760\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    751\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    752\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably loading a A2C/PPO model saved with SB3 < 1.7.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwe deactivated exact_match so you can save the model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: the model should still work fine, this only a warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m         )\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 760\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;66;03m# Patch to load DQN policies saved using SB3 < 2.4.0\u001b[39;00m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# The target network params are no longer in the optimizer\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# See https://github.com/DLR-RM/stable-baselines3/pull/1963\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     saved_optim_params \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy.optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam_groups\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cppo/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:744\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m model\u001b[38;5;241m.\u001b[39m_setup_model()\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# put state_dicts back in place\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;66;03m# Patch to load policies saved using SB3 < 1.7.0\u001b[39;00m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# the error is probably due to old policy being loaded\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# See https://github.com/DLR-RM/stable-baselines3/issues/1233\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi_features_extractor\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/miniconda3/envs/cppo/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:633\u001b[0m, in \u001b[0;36mBaseAlgorithm.set_parameters\u001b[0;34m(self, load_path_or_dict, exact_match, device)\u001b[0m\n\u001b[1;32m    630\u001b[0m         attr\u001b[38;5;241m.\u001b[39mload_state_dict(params[name])  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;66;03m# Assume attr is th.nn.Module\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m         \u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_match\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     updated_objects\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_match \u001b[38;5;129;01mand\u001b[39;00m updated_objects \u001b[38;5;241m!=\u001b[39m objects_needing_update:\n",
      "File \u001b[0;32m~/miniconda3/envs/cppo/lib/python3.9/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for QuantizedActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.act1.x_min: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for mlp_extractor.policy_net.act1.x_max: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for mlp_extractor.policy_net.act1.act_scaling_factor: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for action_net.act2.x_min: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for action_net.act2.x_max: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for action_net.act2.act_scaling_factor: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"/home/ritwik/MuJoCo_Quant/logs_ant/best_model_fixscale_1/best_model.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de834c1a",
   "metadata": {},
   "source": [
    "# Get the scales and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "517b0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_frexp_refactored(inputs):\n",
    "    \"\"\"\n",
    "    Decompose the scaling factor into mantissa and twos exponent, ensuring:\n",
    "    - Mantissa lies in [0, 2^16)\n",
    "    - Exponent remains meaningful (adjusted to match the scaled mantissa)\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    inputs: Tensor\n",
    "        Scaling factor\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    mantissa: Tensor\n",
    "    exponent: Tensor\n",
    "    \"\"\"\n",
    "    shape_of_input = inputs.size()\n",
    "\n",
    "    # Flatten the input tensor to a 1D tensor\n",
    "    inputs = inputs.view(-1)\n",
    "\n",
    "    # Decompose into mantissa and exponent\n",
    "    output_m, output_e = np.frexp(inputs.cpu().numpy())\n",
    "\n",
    "    # Prepare adjusted mantissa and exponent lists\n",
    "    tmp_m = []\n",
    "    tmp_e = []\n",
    "\n",
    "    # Define the bias to scale mantissa to [0, 2^16)\n",
    "    scale_factor = 16  # 2^16\n",
    "\n",
    "    for idx, (m, e) in enumerate(zip(output_m, output_e)):\n",
    "        # Scale mantissa from [0.5, 1) to [0, 2^16)\n",
    "        int_m_shifted = int(Decimal(m * (2 ** scale_factor)).quantize(Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
    "\n",
    "        # Adjust the exponent to account for the scaling of the mantissa\n",
    "        e -= scale_factor\n",
    "        e= e*-1\n",
    "        e = max(0, min(255, e))\n",
    "        # Ensure mantissa and exponent are within valid bounds\n",
    "        if int_m_shifted >= 2 ** 16:  # Cap mantissa at maximum (65535)\n",
    "            int_m_shifted = 2 ** 16 - 1\n",
    "\n",
    "        elif inputs[idx] >= 65535:\n",
    "            int_m_shifted = 65535\n",
    "            e = 0\n",
    "\n",
    "        tmp_m.append(int_m_shifted)\n",
    "        tmp_e.append(e)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # tensor = torch.tensor(0.).to(device)\n",
    "\n",
    "    return torch.from_numpy(np.array(tmp_m)).to(device).view(shape_of_input), \\\n",
    "           torch.from_numpy(np.array(tmp_e)).to(device).view(shape_of_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bef47da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0037])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf15e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx = state_dict['mlp_extractor.policy_net.act1.act_scaling_factor']\n",
    "Sw = state_dict['mlp_extractor.policy_net.fc1.fc_scaling_factor']\n",
    "Sx1 = state_dict['mlp_extractor.policy_net.act2.act_scaling_factor']\n",
    "Sw1 = state_dict['mlp_extractor.policy_net.fc2.fc_scaling_factor']\n",
    "# Sx2 = state_dict['mlp_extractor.policy_net.act3.act_scaling_factor']\n",
    "Sw2 = state_dict['action_net.fc1.fc_scaling_factor']\n",
    "Sx2 = state_dict['action_net.act1.act_scaling_factor']\n",
    "Sw3= state_dict['action_net.fc1.fc_scaling_factor'] \n",
    "Sx3 = state_dict['action_net.act2.act_scaling_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87cf6204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1747e-06])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sx2*Sw3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8faf04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m0, e0 = batch_frexp_refactored(Sx)\n",
    "m1, e1 = batch_frexp_refactored(Sw*Sx/Sx1)\n",
    "m2, e2 = batch_frexp_refactored(Sw1*Sx1/Sx2)\n",
    "m3, e3 = batch_frexp_refactored(Sx2*Sw2/Sx3)\n",
    "\n",
    "w1 = state_dict['mlp_extractor.policy_net.fc1.weight_integer']\n",
    "b1 = state_dict['mlp_extractor.policy_net.fc1.bias_integer']\n",
    "w2 = state_dict['mlp_extractor.policy_net.fc2.weight_integer']\n",
    "b2 = state_dict['mlp_extractor.policy_net.fc2.bias_integer']\n",
    "w3 = state_dict['action_net.fc1.weight_integer']\n",
    "b3 = state_dict['action_net.fc1.bias_integer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b09465e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Ant-v5')\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e8b05c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.72609608,  0.97502791, -0.00550536,  0.01237795,  0.07291184,\n",
       "        -0.0789343 , -0.0252412 ,  0.09569585,  0.08525837,  0.07520057,\n",
       "         0.04386474,  0.00606424, -0.02980362,  0.0626841 , -0.07022213,\n",
       "        -0.03829926, -0.08660343, -0.12020378, -0.04911877, -0.10811243,\n",
       "        -0.15067203, -0.04501276,  0.05172145,  0.01603967, -0.02342684,\n",
       "         0.00700051,  0.03747318,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " {'x_position': 0.09663855973414343,\n",
       "  'y_position': -0.054416160333245034,\n",
       "  'distance_from_origin': 0.11090594994364837})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72769bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "obs_=env.reset()\n",
    "# import torch\n",
    "# obs_quant = torch.round(torch.tensor(obs_req)*2**e0/m0).to(torch.float32)\n",
    "# print(obs_quant)\n",
    "# a1 = torch.round((torch.matmul(obs_quant,w1.T)+b1)*m1/2**e1)\n",
    "# a1 = torch.relu(a1)\n",
    "# a1 = torch.clip(a1, 0, 255)\n",
    "# print(a1)\n",
    "# a2 = torch.round((torch.matmul(a1,w2.T)+b2)*m2/2**e2)\n",
    "# a2 = torch.relu(a2)\n",
    "# a2 = torch.clip(a2, 0, 255)\n",
    "# print(a2)\n",
    "# a3 = torch.round((torch.matmul(a2,w3.T)+b3)*m3/2**e3)\n",
    "# a3 = torch.clip(a3, -127, 127)\n",
    "# print(a3)\n",
    "\n",
    "def forward_pass(obs):\n",
    "    obs_quant = torch.round(torch.tensor(obs)*2**e0/m0).to(torch.float32)\n",
    "    a1 = torch.round((torch.matmul(obs_quant,w1.T)+b1)*m1/2**e1)\n",
    "    a1 = torch.relu(a1)\n",
    "    a2 = torch.round((torch.matmul(a1,w2.T)+b2)*m2/2**e2)\n",
    "    a2 = torch.relu(a2)\n",
    "    a3 = torch.round((torch.matmul(a2,w3.T)+b3)*m3/2**e3)\n",
    "\n",
    "    return a3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4bae179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3723589072438309"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "780b924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000,  0.0249, -0.0373, -0.0000, -0.0373,  0.0622,  0.0000,  0.0498])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(obs)*2**e3/m3*Sw3*Sx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee622945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000,  0.0124, -0.0498, -0.0124, -0.0373,  0.0498,  0.0124,  0.0498])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(obs)*Sx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6791698d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.71079313e-01,  9.93715344e-01,  9.75758965e-03, -7.45706249e-02,\n",
       "        8.29085402e-02, -1.21863137e-01,  8.64816961e-01, -8.36181849e-03,\n",
       "       -8.32872007e-01, -6.47045660e-02, -8.74590321e-01,  1.59677392e-02,\n",
       "        8.58528053e-01, -1.55063724e-01, -4.02453615e-02, -5.48605858e-01,\n",
       "        4.65907036e-02, -5.52429561e-03,  1.04598326e-01, -6.70952645e-01,\n",
       "        8.53270053e+00, -4.74178474e-01, -7.75348259e+00,  2.63192802e-01,\n",
       "       -8.78298936e+00,  4.54328995e-02,  8.31510100e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af03c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952.1005827143886\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "timestep=0\n",
    "obs = env.reset()\n",
    "total_reward= 0\n",
    "done = False\n",
    "while not done and timestep < 1000:\n",
    "    # print(\"YY\")\n",
    "    # if timestep==0:\n",
    "    #     action = forward_pass(obs[0])*Sx3\n",
    "    # else:\n",
    "    #     action = forward_pass(obs)*Sx3\n",
    "    # action = action.cpu().numpy()\n",
    "    if timestep ==0:\n",
    "        action, _ = model.policy.predict(obs[0], deterministic=True)\n",
    "    else:\n",
    "        action, _ = model.policy.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    obs_req = obs\n",
    "    # break\n",
    "    done = terminated or truncated\n",
    "    # if done:\n",
    "        # print(timestep)\n",
    "    total_reward += reward\n",
    "    timestep+=1\n",
    "print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa202da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4460db65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04891392,  0.01510577, -0.00719322, -0.06617766,  0.06186172,\n",
       "        0.04028205, -0.09135394, -0.0805641 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c729c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_quant_save = obs_quant.cpu().numpy().reshape(-1, 1)\n",
    "a1_save = a1.cpu().numpy().reshape(-1, 1)\n",
    "a2_save = a2.cpu().numpy().reshape(-1, 1)\n",
    "a3_save = a3.cpu().numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb4c24",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "w1_save = w1.cpu().numpy()\n",
    "w2_save = w2.cpu().numpy()\n",
    "w3_save = w3.cpu().numpy()\n",
    "\n",
    "b1_save = b1.cpu().numpy().reshape(-1,1)\n",
    "b2_save = b2.cpu().numpy().reshape(-1,1)\n",
    "b3_save = b3.cpu().numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8534eedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_quant_save.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "657277fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[39279]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52989139",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"Activation\")\n",
    "path1 = \"./Activation/\"\n",
    "np.savetxt(path1+\"obs_quant.csv\", obs_quant_save.T, delimiter=\",\", fmt=\"%.6f\")\n",
    "np.savetxt(path1+\"a1.csv\", a1_save.T, delimiter=\",\", fmt=\"%.6f\")\n",
    "np.savetxt(path1+\"a2.csv\", a2_save.T, delimiter=\",\", fmt=\"%.6f\")\n",
    "np.savetxt(path1+\"a3.csv\", a3_save.T, delimiter=\",\",fmt=\"%.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fd426027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.mkdir(\"Activation\")\n",
    "\n",
    "os.mkdir(\"Parameters\")\n",
    "path1 = \"./Activation/\"\n",
    "path2 = \"./Parameters/\"\n",
    "np.savetxt(path1+\"obs_quant.csv\", obs_quant_save.T, delimiter=\",\", fmt=\"%.6f\")\n",
    "np.savetxt(path1+\"a1.csv\", a1_save.T, delimiter=\",\", fmt=\"%.6f\")\n",
    "np.savetxt(path1+\"a2.csv\", a2_save.T, delimiter=\",\", fmt=\"%.6f\")\n",
    "np.savetxt(path1+\"a3.csv\", a3_save.T, delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path2+\"fc1_weight.csv\", w1_save.T, delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path2+\"fc2_weight.csv\", w2_save.T, delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path2+\"fc3_weight.csv\", w3_save.T, delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path2+\"fc1_bias.csv\", b1_save.T, delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path2+\"fc2_bias.csv\", b2_save.T, delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path2+\"fc3_bias.csv\", b3_save.T, delimiter=\",\",fmt=\"%.6f\")\n",
    "# np.save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3547cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"Scales\")\n",
    "path = \"./Scales/\"\n",
    "\n",
    "np.savetxt(path+\"m0.csv\", m0.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path+\"e0.csv\", e0.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path+\"m1.csv\", m1.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path+\"e1.csv\", e1.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path+\"m2.csv\", m2.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path+\"e2.csv\", e2.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path+\"m3.csv\", m3.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")\n",
    "np.savetxt(path+\"e3.csv\", e3.reshape(-1,1).cpu().numpy(), delimiter=\",\",fmt=\"%.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c948c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d85373c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:176] . file in archive is not in a subdirectory: data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ritwik/MuJoCo_Quant/logs_ant/best_model_fixscale_1/best_model.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cppo/lib/python3.9/site-packages/torch/serialization.py:1486\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1484\u001b[0m orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1485\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1486\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m   1488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1489\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1490\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1492\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1493\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/cppo/lib/python3.9/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer: Union[\u001b[38;5;28mstr\u001b[39m, IO[\u001b[38;5;28mbytes\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:176] . file in archive is not in a subdirectory: data"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "params = torch.load(\"/home/ritwik/MuJoCo_Quant/logs_ant/best_model_fixscale_1/best_model.zip\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b88c7e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_net\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.value_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924400a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cppo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
